{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatildaBeinat/KCL-Thesis-data-extraction/blob/main/ML_thesis_KCL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKzjK2nlUWzk"
      },
      "source": [
        "#1 **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAgu4i6g4WE2"
      },
      "outputs": [],
      "source": [
        "!pip install catboost\n",
        "!pip install shap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import shap\n",
        "shap.initjs()\n",
        "import statsmodels.api as sm\n",
        "from catboost import CatBoostClassifier, Pool, metrics, cv\n",
        "from catboost import FeaturesData\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, precision_recall_curve, roc_curve, auc, roc_auc_score, average_precision_score\n",
        "from sklearn.utils import resample\n",
        "from datetime import date, datetime\n",
        "import time\n",
        "from csv import writer\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1BLIKgbWNg0"
      },
      "source": [
        "# Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWCnybbgUDci"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yt_4-Gmsbifp"
      },
      "source": [
        "# Process the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBSz0k6Y47su",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Get and merge data\n",
        "file_features = \"/content/drive/MyDrive/Matilda thesis/official/Features 2000-2023 clean for ML with labels.csv\"\n",
        "file_tsne_concepts = \"/content/drive/MyDrive/Matilda thesis/official/data concepts tsne ML.csv\"\n",
        "file_years = \"/content/drive/MyDrive/Matilda thesis/official/id + years.csv\"\n",
        "file_TSVD = \"/content/drive/MyDrive/Matilda thesis/official/TSVD.csv\"\n",
        "file_rac = \"/content/drive/MyDrive/Matilda thesis/official/one hot encoding rac.csv\"\n",
        "file_rcdc = \"/content/drive/MyDrive/Matilda thesis/official/category rcdc tsne ML.csv\"\n",
        "\n",
        "file_features = pd.read_csv(file_features)\n",
        "file_tsne_concepts = pd.read_csv(file_tsne_concepts)\n",
        "file_years = pd.read_csv(file_years)\n",
        "file_TSVD = pd.read_csv(file_TSVD)\n",
        "file_rac = pd.read_csv(file_rac)\n",
        "file_rcdc = pd.read_csv(file_rcdc)\n",
        "\n",
        "file_features.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
        "file_tsne_concepts.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
        "file_years.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
        "file_TSVD.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
        "file_rac.drop(['Unnamed: 0', 'Unnamed: 2'],axis=1,inplace=True)\n",
        "file_rcdc.drop(['Unnamed: 0', 'Unnamed: 0.1', 'Label'],axis=1,inplace=True)\n",
        "\n",
        "df_orig = file_features.merge(file_tsne_concepts, on='id')\n",
        "df_orig = df_orig.merge(file_years, on='id')\n",
        "df_orig = df_orig.merge(file_TSVD, on='id')\n",
        "df_orig = df_orig.merge(file_rac, on='id')\n",
        "df_orig = df_orig.merge(file_rcdc, on='id')\n",
        "\n",
        "# df_orig contains the full datasets loaded from files, and merged\n",
        "\n",
        "# we use three data frames\n",
        "# df_orig = ORIGINAL - the original data loaded from the file\n",
        "# df_p = PROCESED - the processed data with changed data types, removed NaNs etc, columns translated into strings\n",
        "# df = SELECTED COLUMNS FOR ML - is the ML frame, which includes only the colums used for training\n",
        "\n",
        "#@markdown ##### Years range from 2000-2023\n",
        "final_year = 2018 #@param {type:\"number\"}\n",
        "\n",
        "#@title Convert values into string and fill missing values\n",
        "# Convert column 'journal.id and first author id in to strings\n",
        "df_p = df_orig.copy()\n",
        "df_p['journal.id'] = df_p['journal.id'].astype(str)\n",
        "df_p['first_author_id'] = df_p['first_author_id'].astype(str)\n",
        "\n",
        "# Add 'no_value' to categorical features\n",
        "\n",
        "# Fill missing values with 'missing_value'\n",
        "if 'category_hrcs_rac_clean' in df_p.columns: df_p['category_hrcs_rac_clean'].fillna('no_value', inplace=True)\n",
        "if 'category_hra_clean' in df_p.columns: df_p['category_hra_clean'].fillna('no_value', inplace=True)\n",
        "if 'category_rcdc_clean' in df_p.columns: df_p['category_rcdc_clean'].fillna('no_value', inplace=True)\n",
        "if 'mesh_terms' in df_p.columns: df_p['mesh_terms'].fillna('no_value', inplace=True)\n",
        "if 'open_access' in df_p.columns: df_p['open_access'].fillna('no_value', inplace=True)\n",
        "if 'journal.id' in df_p.columns: df_p['journal.id'].fillna('no_value', inplace=True)\n",
        "if 'supporting_grant_ids' in df_p.columns: df_p['supporting_grant_ids'].fillna('no_value', inplace=True)\n",
        "if 'first_author_id' in df_p.columns: df_p['first_author_id'].fillna('no_value', inplace=True)\n",
        "if 'Author_name' in df_p.columns: df_p['Author_name'].fillna('no_value', inplace=True)\n",
        "if 'first_author_affiliation_id' in df_p.columns: df_p['first_author_affiliation_id'].fillna('no_value', inplace=True)\n",
        "if 'first_author_affiliation_country' in df_p.columns: df_p['first_author_affiliation_country'].fillna('no_value', inplace=True)\n",
        "\n",
        "df_all = df_p.copy()\n",
        "df_p = df_p [df_p ['year']<=final_year]\n",
        "print(f\"Rows: {df_orig.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNU4EakEyIW4"
      },
      "source": [
        "# Set parameters and columns for the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31dAeY5KWr0_",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Select Parameters\n",
        "#@markdown ##Model Settings\n",
        "test_perc = 0.3 #@param {type: \"number\"}\n",
        "metric = 'Accuracy' #@param [\"Accuracy\", \"Precision\" , \"Recall\" , \"F1\", \"CrossEntropy\"]\n",
        "\n",
        "#@markdown ##Select Training\n",
        "training_selection = \"label_trials_patents\" #@param [\"label_patents\", \"label_trials\", \"label_trials_patents\"] {type:\"string\"}\n",
        "training_remove = [\"label_patents\", \"label_trials\"]\n",
        "if training_selection == \"label_patents\":\n",
        "  training_remove = [\"label_trials\", \"label_trials_patents\"]\n",
        "if training_selection == \"label_trials\":\n",
        "  training_remove = [\"label_patents\", \"label_trials_patents\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubvRAKm_j6Wa",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Select Columns to Include\n",
        "include_id = False #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown #### TSNE A, B and C\n",
        "include_tsne = True #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown #### TSVD\n",
        "include_TSVD = True #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown #### Categorical Features\n",
        "include_all_cat_features = False #@param {type: \"boolean\"}\n",
        "\n",
        "include_category_hrcs_rac_clean= False #@param {type: \"boolean\"}\n",
        "include_category_hra_clean = True #@param {type: \"boolean\"}\n",
        "include_category_rcdc_clean = False #@param {type: \"boolean\"}\n",
        "include_mesh_terms = True #@param {type: \"boolean\"}\n",
        "include_open_access = True #@param {type: \"boolean\"}\n",
        "include_journal_id = True #@param {type: \"boolean\"}\n",
        "include_supporting_grant_ids = True #@param {type: \"boolean\"}\n",
        "include_first_author_id = True #@param {type: \"boolean\"}\n",
        "include_Author_name = True #@param {type: \"boolean\"}\n",
        "include_first_author_affiliation_id = True #@param {type: \"boolean\"}\n",
        "include_first_author_affiliation_country = True #@param {type: \"boolean\"}\n",
        "if(include_all_cat_features):\n",
        "  include_category_hrcs_rac_clean= True\n",
        "  include_category_hra_clean = True\n",
        "  include_category_rcdc_clean = True\n",
        "  include_mesh_terms = True\n",
        "  include_open_access = True\n",
        "  include_journal_id = True\n",
        "  include_supporting_grant_ids = True\n",
        "  include_first_author_id = True\n",
        "  include_Author_name = True\n",
        "  include_first_author_affiliation_id = True\n",
        "  include_first_author_affiliation_country = True\n",
        "\n",
        "#@markdown #### Other\n",
        "include_authors_count = True #@param {type: \"boolean\"}\n",
        "include_recent_citations = False #@param {type: \"boolean\"}\n",
        "include_times_cited = True #@param {type: \"boolean\"}\n",
        "include_altmetric = True #@param {type: \"boolean\"}\n",
        "include_relative_citation_ratio = True #@param {type: \"boolean\"}\n",
        "include_reference_ids_count = True #@param {type: \"boolean\"}\n",
        "include_count_research_org_country_names = True #@param {type: \"boolean\"}\n",
        "include_count_research_org_names = True #@param {type: \"boolean\"}\n",
        "include_year = False #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown #### Citations and Associations\n",
        "include_citing_patents = False #@param {type: \"boolean\"}\n",
        "include_associated_trials = False #@param {type: \"boolean\"}\n",
        "\n",
        "# drop unnecessary columns\n",
        "# original list of columns  --> Remember to copy the list of features into \"orig_features\" if that changes after reloading the original data\n",
        "# note that the cat_features array is needed by cat boost to treat the features as categorical\n",
        "orig_features = ['id', 'category_hrcs_rac_clean', 'category_hra_clean',\n",
        "       'category_rcdc_clean', 'mesh_terms', 'authors_count', 'open_access',\n",
        "       'recent_citations', 'times_cited', 'journal.id', 'altmetric',\n",
        "       'supporting_grant_ids', 'relative_citation_ratio',\n",
        "       'reference_ids_count', 'first_author_id', 'Author_name',\n",
        "       'first_author_affiliation_id', 'first_author_affiliation_country',\n",
        "       'count_research_org_country_names', 'count_research_org_names',\n",
        "       'Citing patents', 'Associated trials', 'label_patents', 'label_trials',\n",
        "       'a', 'b', 'c', 'Label','0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19']\n",
        "\n",
        "orig_cat_features = ['category_hrcs_rac_clean', 'category_hra_clean', 'category_rcdc_clean', 'mesh_terms', 'open_access', 'journal.id',\n",
        "                      'supporting_grant_ids', 'first_author_id', 'Author_name', 'first_author_affiliation_id', 'first_author_affiliation_country']\n",
        "\n",
        "others = ['authors_count','recent_citations', 'times_cited',  'altmetric','relative_citation_ratio',\n",
        "        'reference_ids_count', 'count_research_org_country_names', 'count_research_org_names', 'year']\n",
        "\n",
        "drop_items = ['Label']\n",
        "\n",
        "\n",
        "drop_items.extend(training_remove)\n",
        "if(not include_id): drop_items.append('id')\n",
        "if(not include_tsne): drop_items.extend(['a','b','c'])\n",
        "if(not include_TSVD): drop_items.extend(['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19'])\n",
        "if(not include_category_hrcs_rac_clean): drop_items.append('category_hrcs_rac_clean')\n",
        "if(not include_category_hra_clean): drop_items.append('category_hra_clean')\n",
        "if(not include_category_rcdc_clean): drop_items.append('category_rcdc_clean')\n",
        "if(not include_mesh_terms): drop_items.append('mesh_terms')\n",
        "if(not include_authors_count): drop_items.append('authors_count')\n",
        "if(not include_open_access): drop_items.append('open_access')\n",
        "if(not include_recent_citations): drop_items.append('recent_citations')\n",
        "if(not include_times_cited): drop_items.append('times_cited')\n",
        "if(not include_journal_id): drop_items.append('journal.id')\n",
        "if(not include_altmetric): drop_items.append('altmetric')\n",
        "if(not include_supporting_grant_ids): drop_items.append('supporting_grant_ids')\n",
        "if(not include_relative_citation_ratio): drop_items.append('relative_citation_ratio')\n",
        "if(not include_reference_ids_count): drop_items.append('reference_ids_count')\n",
        "if(not include_first_author_id): drop_items.append('first_author_id')\n",
        "if(not include_Author_name): drop_items.append('Author_name')\n",
        "if(not include_first_author_affiliation_id): drop_items.append('first_author_affiliation_id')\n",
        "if(not include_first_author_affiliation_country): drop_items.append('first_author_affiliation_country')\n",
        "if(not include_count_research_org_country_names): drop_items.append('count_research_org_country_names')\n",
        "if(not include_count_research_org_names): drop_items.append('count_research_org_names')\n",
        "if(not include_citing_patents): drop_items.append('Citing patents')\n",
        "if(not include_associated_trials): drop_items.append('Associated trials')\n",
        "if(not include_year): drop_items.append('year')\n",
        "\n",
        "df = df_p.drop(drop_items, axis=1)\n",
        "\n",
        "print(\"Remaining features: \" + str([i for i in orig_features if i not in drop_items]))\n",
        "print('')\n",
        "print(\"Dropped features: \" + str(drop_items))\n",
        "print('')\n",
        "\n",
        "# drop the removed columns in cat_feature\n",
        "cat_features = [x for x in orig_cat_features if x not in drop_items]\n",
        "print('Number of categorical features =', len(cat_features))\n",
        "\n",
        "print(\"Total number of features = \" + str(len(df.columns)))\n",
        "print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdxcIOMmulbP",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title  Sampling Settings\n",
        "\n",
        "df_sample = df.copy()\n",
        "down_sampling_mult = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "over_sampling_mult = 1 #@param {type:\"slider\", min:1, max:5, step:1}\n",
        "\n",
        "if(down_sampling_mult !=0):\n",
        "  zero_rows = df_sample[df_sample[training_selection] == 0]\n",
        "  num_rows_to_remove = int(len(zero_rows) * down_sampling_mult)\n",
        "  rows_to_remove = zero_rows.sample(n=num_rows_to_remove, random_state = 42)\n",
        "  df_sample = df_sample.drop(rows_to_remove.index)\n",
        "\n",
        "print(df_sample.shape)\n",
        "print(df_sample[training_selection].sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2lVcAXAW2WW"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwTgwzIM5PoF"
      },
      "outputs": [],
      "source": [
        "target_col = training_selection\n",
        "X = df_sample.loc[:, df_sample.columns != target_col]\n",
        "y = df_sample.loc[:, target_col]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vi_Co5e5qUX"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size = test_perc,\n",
        "                                                    random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82BcEkzG16XA"
      },
      "outputs": [],
      "source": [
        "lst = []\n",
        "for i in range(over_sampling_mult-1):\n",
        "  for i in list(X_train.index.values):\n",
        "    if(str(df_sample[target_col].loc[i])=='1'):\n",
        "      lst.append(list(X_train.loc[i]))\n",
        "\n",
        "count = len(lst)\n",
        "print(count)\n",
        "lst = pd.DataFrame(lst,columns=X_train.columns)\n",
        "\n",
        "X_train = pd.concat([X_train,lst])\n",
        "\n",
        "y_train = y_train.append(pd.Series([1] * count),ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQrgDIy6NVrW"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(f\"Zeros dataframe: {len(df_sample)-df_sample[target_col].sum()}\")\n",
        "print(f\"Ones dataframe: {df_sample[target_col].sum()}\")\n",
        "print(f\"Test percentage: {test_perc}\")\n",
        "print('')\n",
        "print(f\"Zeros training : {len(y_train)-y_train.sum()}\")\n",
        "print(f\"Ones training: {y_train.sum()}\")\n",
        "print('')\n",
        "print(f\"Zeros test : {len(y_test)-y_test.sum()}\")\n",
        "print(f\"Ones test: {y_test.sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ITM3hxNPJRZ"
      },
      "outputs": [],
      "source": [
        "df_sample[target_col].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "br0OqNWp6m63"
      },
      "outputs": [],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeXK9uaaBc-s"
      },
      "outputs": [],
      "source": [
        "features = list(X_train.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48aXcEzc6NQP"
      },
      "outputs": [],
      "source": [
        "model_cb = CatBoostClassifier(task_type='GPU',\n",
        "                              iterations=100,\n",
        "                              random_state = 2021,\n",
        "                              eval_metric = metric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmU3OQJY535k"
      },
      "outputs": [],
      "source": [
        "model_cb.fit(X_train, y_train, cat_features= cat_features, plot=True,\n",
        "             eval_set=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X550kU8D558B"
      },
      "outputs": [],
      "source": [
        "y_pred = model_cb.predict(X_test)\n",
        "y_pred_probs = model_cb.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0j-cqwqPLb4"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwgxoSnsW_jh"
      },
      "source": [
        "# Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRPR6rsH__H_"
      },
      "outputs": [],
      "source": [
        "print('% testing  = ', test_perc)\n",
        "print('metric     = ', metric)\n",
        "print ('')\n",
        "test_count = len(X_test)\n",
        "print('test size  = ', test_count)\n",
        "zero_count = (y_test == 0).sum().sum()\n",
        "print('zeros      = ', zero_count)\n",
        "print('ones       = ', test_count - zero_count)\n",
        "print('prev. zero = ', zero_count/test_count)\n",
        "print ('')\n",
        "print('accuracy   = ', accuracy_score(y_test, y_pred))\n",
        "print('precision  = ', precision_score(y_test, y_pred))\n",
        "print('recall     = ', recall_score(y_test, y_pred))\n",
        "print('F1         = ', f1_score(y_test, y_pred))\n",
        "print('Lift       = ', accuracy_score(y_test, y_pred)-zero_count/test_count)\n",
        "\n",
        "print('cm=', confusion_matrix(y_test, y_pred))\n",
        "\n",
        "#df_sample.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## confusion matrix ML model"
      ],
      "metadata": {
        "id": "KLLQCC5OioK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plot confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plotting using seaborn heatmap for better visualization\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(cm, annot=True, fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')"
      ],
      "metadata": {
        "id": "V0GoFhBDrEXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ROC curve ML model"
      ],
      "metadata": {
        "id": "QeMhyt-YiQfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#compute ROC curve for ML models\n",
        "#select the column of probabilities for \"1\", which is the second column of y_pred_probs\n",
        "y_pred_prob1 = y_pred_probs[:, 1]\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob1)\n",
        "\n",
        "# Compute ROC area\n",
        "roc_auc = auc(fpr, tpr)\n",
        "# Plot ROC curve\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange',\n",
        "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic example')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j6v3XNMrFt-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Precision-recall curve ML model"
      ],
      "metadata": {
        "id": "Y0xFNj-JiUsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#compute precision recall curve for ML models\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_prob1)\n",
        "\n",
        "plt.plot(recall, precision)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AuuWPHKHGDCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Validation"
      ],
      "metadata": {
        "id": "uV-b0yLyiDZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Validation 0s = 1s\n",
        "\n",
        "# Set the start year for the out-of-time validation data\n",
        "validation_start_year = 2019\n",
        "\n",
        "# Create a copy of the original DataFrame to avoid modifying it\n",
        "df_val = df_all.copy()\n",
        "\n",
        "# Filter the DataFrame to only include rows where the 'year' column is greater than or equal to the validation start year\n",
        "df_val = df_val[df_val['year'] >= validation_start_year]\n",
        "\n",
        "# Separate majority and minority classes\n",
        "df_majority = df_val[df_val[training_selection]==0]\n",
        "df_minority = df_val[df_val[training_selection]==1]\n",
        "\n",
        "# Downsample majority class\n",
        "df_majority_downsampled = resample(df_majority,\n",
        "                                 replace=False,    # sample without replacement\n",
        "                                 n_samples=len(df_minority),     # to match minority class\n",
        "                                 random_state=123) # reproducible results\n",
        "\n",
        "# Combine minority class with downsampled majority class\n",
        "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
        "\n",
        "# Display new class counts\n",
        "print(df_downsampled[training_selection].value_counts())\n",
        "\n",
        "# Create a copy of the list of columns to drop\n",
        "drop_items_val = drop_items.copy()\n",
        "\n",
        "# Drop the specified columns from the validation DataFrame\n",
        "df_downsampled = df_downsampled.drop(drop_items_val, axis=1)\n",
        "\n",
        "# Extract the actual target values for the validation data\n",
        "y_real = df_downsampled[training_selection].to_numpy()\n",
        "\n",
        "# Drop the target column from the validation DataFrame\n",
        "df_downsampled = df_downsampled.drop(training_selection, axis=1)\n",
        "\n",
        "# Use the trained model to make predictions on the validation data\n",
        "y_pred_val = model_cb.predict(df_downsampled)\n",
        "\n",
        "# Print the performance metrics\n",
        "print('Accuracy  = ', accuracy_score(y_real, y_pred_val))\n",
        "print('Precision = ', precision_score(y_real, y_pred_val))\n",
        "print('Recall    = ', recall_score(y_real, y_pred_val))\n",
        "print('F1 Score  = ', f1_score(y_real, y_pred_val))"
      ],
      "metadata": {
        "id": "6LKRNnpDls3y",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## confusion matrix validation"
      ],
      "metadata": {
        "id": "nouW2z0biH_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plot confusion matrix for validation\n",
        "cm = confusion_matrix(y_real, y_pred_val)\n",
        "\n",
        "# Plotting using seaborn heatmap for better visualization\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(cm, annot=True, fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')"
      ],
      "metadata": {
        "id": "ISkVLHl5xeDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ROC curve Validation"
      ],
      "metadata": {
        "id": "GHdjfvdMizLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the trained model to predict probabilities for the validation data\n",
        "y_pred_val_proba = model_cb.predict_proba(df_downsampled)[:, 1]\n",
        "\n",
        "# Calculate the ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_real, y_pred_val_proba)\n",
        "\n",
        "# Calculate the AUC (area under the ROC curve)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QJ1F7Pahi102"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Precision-recall curve validation"
      ],
      "metadata": {
        "id": "4UooqlTei2Xe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the trained model to predict probabilities for the validation data\n",
        "y_pred_val_proba = model_cb.predict_proba(df_downsampled)[:, 1]\n",
        "\n",
        "# Calculate the Precision-Recall curve\n",
        "precision, recall, _ = precision_recall_curve(y_real, y_pred_val_proba)\n",
        "\n",
        "# Plot the Precision-Recall curve\n",
        "plt.plot(recall, precision)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1hsepySfi53H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add results to CSV file"
      ],
      "metadata": {
        "id": "ZOTlkHyqiYjq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fogSS-_bpAYC"
      },
      "outputs": [],
      "source": [
        "#@title Add results to the Results.csv file\n",
        "\n",
        "curr_time = time.strftime(\"%H:%M:%S\", time.gmtime())\n",
        "date_time = str(date.today()) + \" \" +curr_time\n",
        "\n",
        "ones_orig = df_p[training_selection].sum()\n",
        "zeros_orig = len(df_p) - ones_orig\n",
        "\n",
        "ones_post = df_sample[training_selection].sum()\n",
        "zeros_post = len(df_sample) - ones_post\n",
        "\n",
        "additive = [date_time, final_year, training_selection, df_p.shape[0], df_p.shape[1], zeros_orig, ones_orig, down_sampling_mult, over_sampling_mult,  df_sample.shape[0], df_sample.shape[1], zeros_post, ones_post, test_perc, metric, zero_count/test_count, accuracy_score(y_test, y_pred), precision_score(y_test, y_pred), recall_score(y_test, y_pred), f1_score(y_test, y_pred), accuracy_score(y_test, y_pred)-zero_count/test_count, include_id, include_tsne, include_TSVD, include_category_hrcs_rac_clean, include_category_hra_clean, include_category_rcdc_clean, include_mesh_terms, include_open_access, include_journal_id, include_supporting_grant_ids, include_first_author_id, include_Author_name, include_first_author_affiliation_id, include_first_author_affiliation_country, include_authors_count, include_recent_citations, include_times_cited, include_altmetric, include_relative_citation_ratio, include_reference_ids_count, include_count_research_org_country_names, include_count_research_org_names, include_year, include_citing_patents, include_associated_trials]\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Matilda thesis/official/Final/Results.csv\", 'a') as f_object:\n",
        "    writer_object = writer(f_object)\n",
        "    writer_object.writerow(additive)\n",
        "    f_object.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get SHAP values"
      ],
      "metadata": {
        "id": "Gju7dQ4wi7yJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqQuKzJHGGot"
      },
      "outputs": [],
      "source": [
        "#Get shap values\n",
        "explainer = shap.Explainer(model_cb)\n",
        "shap_values = explainer(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5bKsEZSHCbW"
      },
      "outputs": [],
      "source": [
        "# Waterfall plot for first observation\n",
        "shap.plots.waterfall(shap_values[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.beeswarm(shap_values)"
      ],
      "metadata": {
        "id": "kOqXg_ET5CNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_names_full = X_test.columns.tolist()\n",
        "#column_names = column_names_full[2:]\n",
        "column_names_full\n",
        "\n",
        "#shap.summary_plot(shap_values, X_test, feature_names=['Feature '+str(i) for i in range(X_test.shape[1])])"
      ],
      "metadata": {
        "id": "48utI_H0N962"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5cJugIXHWqC"
      },
      "outputs": [],
      "source": [
        "shap.plots.scatter(shap_values[:,\"times_cited\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rQz8GLxvamp",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Create the results csv file, only do this once\n",
        "# dont forget to add to the \"additive\" variable in the cell above if you add something here\n",
        "columns = [\"Date and Time\", \"Final Year\",  \"Label\", \"Number Rows Orig\", \"Number Features Orig\", \"Zeros Orig\", \"Ones Orig\", \"Downsampling\", \"Oversampling\", \"Number Rows Post\", \"Number Features Post\", \"Zeros Post\", \"Ones Post\", \"Test Percentage\", \"Metric\", \"Prevalence of Zeros\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"Lift\", \"include_id\", \"include_tsne\", \"include_TSVD\", \"include_category_hrcs_rac_clean\", \"include_category_hra_clean\", \"include_category_rcdc_clean\", \"include_mesh_terms\", \"include_open_access\", \"include_journal_id\", \"include_supporting_grant_ids\", \"include_first_author_id\", \"include_Author_name\", \"include_first_author_affiliation_id\", \"include_first_author_affiliation_country\", \"include_authors_count\", \"include_recent_citations\", \"include_times_cited\", \"include_altmetric\", \"include_relative_citation_ratio\", \"include_reference_ids_count\", \"include_count_research_org_country_names\", \"include_count_research_org_names\", \"include_year\", \"include_citing_patents\", \"include_associated_trials\"]\n",
        "results = pd.DataFrame(columns=columns)\n",
        "results.to_csv(\"/content/drive/MyDrive/Matilda thesis/official/Final/Results.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "LKzjK2nlUWzk",
        "c1BLIKgbWNg0",
        "D2lVcAXAW2WW"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}