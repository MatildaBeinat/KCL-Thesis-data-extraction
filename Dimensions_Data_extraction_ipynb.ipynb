{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatildaBeinat/KCL-Thesis-data-extraction/blob/main/Dimensions_Data_extraction_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "VhOOop8KOtU2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQlPYIX8XoF0"
      },
      "outputs": [],
      "source": [
        "!pip install dimcli tqdm plotly -U --quiet\n",
        "\n",
        "import dimcli\n",
        "from dimcli.utils import *\n",
        "\n",
        "import sys, time, json\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm as progressbar\n",
        "import numpy as np\n",
        "import ast\n",
        "\n",
        "import plotly.express as px\n",
        "if not 'google.colab' in sys.modules:\n",
        "  # make js dependecies local / needed by html exports\n",
        "  from plotly.offline import init_notebook_mode\n",
        "  init_notebook_mode(connected=True)\n",
        "\n",
        "print(\"==\\nLogging in..\")\n",
        "# https://digital-science.github.io/dimcli/getting-started.html#authentication\n",
        "ENDPOINT = \"https://app.dimensions.ai\"\n",
        "if 'google.colab' in sys.modules:\n",
        "  import getpass\n",
        "  KEY = getpass.getpass(prompt='API Key: ')\n",
        "  dimcli.login(key=KEY, endpoint=ENDPOINT)\n",
        "else:\n",
        "  KEY = \"\"\n",
        "  dimcli.login(key=KEY, endpoint=ENDPOINT)\n",
        "dsl = dimcli.Dsl()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY83LHCeKCK8",
        "outputId": "e2b8f33f-fe61-47b1-ae0c-cc7dacc5d9fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R44ucUbJDZpx"
      },
      "source": [
        "# Feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tqvet6rJ9S8"
      },
      "source": [
        "## Original dataset: feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnwrraXaFcge"
      },
      "source": [
        "### Full\n",
        "Chunk it due to size of records.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7h71QXxvGLU"
      },
      "outputs": [],
      "source": [
        "df1 = dsl.query_iterative(f\"\"\"\n",
        "                search publications\n",
        "                in title_abstract_only for \"dementia OR alzheimer*\"\n",
        "                where (research_org_countries = \"GB\"\n",
        "                and year in [2000:2023])\n",
        "                return publications[\n",
        "                id+\n",
        "                mesh_terms+\n",
        "                category_hra+\n",
        "                category_hrcs_rac+\n",
        "                category_rcdc\n",
        "                ]\"\"\").as_dataframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0lOhsGMvSn8"
      },
      "outputs": [],
      "source": [
        "df2 = dsl.query_iterative(f\"\"\"\n",
        "                search publications\n",
        "                in title_abstract_only for \"dementia OR alzheimer*\"\n",
        "                where (research_org_countries = \"GB\"\n",
        "                and year in [2000:2023])\n",
        "                return publications[\n",
        "                id+\n",
        "                reference_ids+\n",
        "                recent_citations+\n",
        "                altmetric+\n",
        "                relative_citation_ratio+\n",
        "                times_cited+\n",
        "                authors+\n",
        "                authors_count+\n",
        "                funder_countries+\n",
        "                funders+\n",
        "                journal+\n",
        "                open_access+\n",
        "                research_org_names+\n",
        "                research_org_country_names+\n",
        "                supporting_grant_ids\n",
        "                ]\"\"\").as_dataframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fd7-GDVavpde"
      },
      "outputs": [],
      "source": [
        "UK_dementia_publications = df1.merge(df2, on=\"id\")\n",
        "UK_dementia_publications.to_csv(\"/content/drive/MyDrive/Matilda thesis/UK dementia publications.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irRt1mKhy581"
      },
      "outputs": [],
      "source": [
        "UK_dementia_publications = pd.read_csv(\"/content/drive/MyDrive/Matilda thesis/UK dementia publications.csv\")\n",
        "UK_dementia_publications.drop('Unnamed: 0', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvemdwG3KH68"
      },
      "source": [
        "### Data wrangling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-avaYyBPTeL"
      },
      "source": [
        "extract information about the author and research organisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Je1P-Jq9ISvD"
      },
      "outputs": [],
      "source": [
        "# Count the number of IDs in the reference_ids column\n",
        "UK_dementia_publications['reference_ids_count'] = UK_dementia_publications['reference_ids'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
        "\n",
        "# Drop the reference_ids column\n",
        "UK_dementia_publications.drop('reference_ids', axis=1, inplace=True)\n",
        "\n",
        "\n",
        "# Define a function to extract information about the first author\n",
        "def extract_first_author_info(authors_info):\n",
        "    if authors_info:\n",
        "        first_author = authors_info[0]\n",
        "        if first_author['affiliations']:\n",
        "            first_affiliation = first_author['affiliations'][0]\n",
        "            author_name = f\"{first_author.get('first_name', '')} {first_author.get('last_name', '')}\"\n",
        "            return (first_author.get('researcher_id', None), author_name,\n",
        "                    first_affiliation.get('id', None),\n",
        "                    first_affiliation.get('name', None), first_affiliation.get('country', None))\n",
        "        else:\n",
        "            author_name = f\"{first_author.get('first_name', '')} {first_author.get('last_name', '')}\"\n",
        "            return (first_author.get('researcher_id', None), author_name, None, None, None)\n",
        "    else:\n",
        "        return (None, None, None, None, None)\n",
        "\n",
        "# Apply the function to the authors column to create new columns with first author information\n",
        "(first_author_id, author_name,\n",
        " first_author_affiliation_id, first_author_affiliation_name, first_author_affiliation_country) = \\\n",
        "    zip(*UK_dementia_publications['authors'].apply(extract_first_author_info))\n",
        "\n",
        "UK_dementia_publications['first_author_id'] = first_author_id\n",
        "UK_dementia_publications['Author_name'] = author_name\n",
        "UK_dementia_publications['first_author_affiliation_id'] = first_author_affiliation_id\n",
        "UK_dementia_publications['first_author_affiliation_name'] = first_author_affiliation_name\n",
        "UK_dementia_publications['first_author_affiliation_country'] = first_author_affiliation_country\n",
        "\n",
        "# Drop the authors column\n",
        "UK_dementia_publications.drop('authors', axis=1, inplace=True)\n",
        "\n",
        "#Count number of countries\n",
        "# Check if 'research_org_country_names' is a list\n",
        "if isinstance(UK_dementia_publications['research_org_country_names'].iloc[0], list):\n",
        "    # If it's a list, count the number of elements in the list\n",
        "    UK_dementia_publications['count_research_org_country_names'] = UK_dementia_publications['research_org_country_names'].apply(len)\n",
        "else:\n",
        "    # If it's a string (country names are separated by a delimiter such as comma), split the string by the delimiter and count the number of elements\n",
        "    UK_dementia_publications['count_research_org_country_names'] = UK_dementia_publications['research_org_country_names'].apply(lambda x: len(x.split(',')))\n",
        "\n",
        "\n",
        "#Count number of research_orgs\n",
        "# Check if 'research_org_names' is a list\n",
        "if isinstance(UK_dementia_publications['research_org_names'].iloc[0], list):\n",
        "    # If it's a list, count the number of elements in the list\n",
        "    UK_dementia_publications['count_research_org_names'] = UK_dementia_publications['research_org_names'].apply(len)\n",
        "else:\n",
        "    # If it's a string (country names are separated by a delimiter such as comma), split the string by the delimiter and count the number of elements\n",
        "    UK_dementia_publications['count_research_org_names'] = UK_dementia_publications['research_org_names'].apply(lambda x: len(x.split(',')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOl0bStv8RUL"
      },
      "source": [
        "## PUBLICATIONS cited by patents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX6S07629Hnb"
      },
      "source": [
        "### Adding number of patent citations to UK_dementia_publications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cV4ExG1a8USG"
      },
      "outputs": [],
      "source": [
        "# Create a list of your publications\n",
        "pubsids = list(UK_dementia_publications[\"id\"])\n",
        "\n",
        "# Create a query and run through publications in chunks, there are too many results to process at once otherwise\n",
        "pubs_chunks = dsl.query_iterative(f\"\"\"\n",
        "search publications\n",
        "in title_abstract_only for \"dementia OR alzheimer*\"\n",
        "where (research_org_countries = \"GB\"\n",
        "and year in [2000:2023])\n",
        "return publications[id]\"\"\").chunks(500)\n",
        "\n",
        "# Search for patents for the publications in the list created\n",
        "query_results = []\n",
        "\n",
        "for c in pubs_chunks:\n",
        "\n",
        "      pubslist = json.dumps(list(pd.DataFrame(c).id))\n",
        "\n",
        "      query_results.append(\n",
        "\n",
        "                  dsl.query_iterative(f\"\"\"\n",
        "                        search patents\n",
        "                            where publication_ids in {pubslist}\n",
        "                            return patents[basics+publication_ids]\n",
        "                        \"\"\").as_dataframe()\n",
        "      )\n",
        "\n",
        "# Concatenate the patents to the publication list based on the id\n",
        "Patents_citing_UK_pubs = pd.concat(query_results).\\\n",
        "   drop_duplicates(subset='id')\n",
        "\n",
        "if 'publication_ids' in Patents_citing_UK_pubs:\n",
        "    # turning lists into strings to ensure compatibility with CSV loaded data\n",
        "    # see also: https://stackoverflow.com/questions/23111990/pandas-dataframe-stored-list-as-string-how-to-convert-back-to-list\n",
        "    Patents_citing_UK_pubs['publication_ids'] = Patents_citing_UK_pubs['publication_ids'].apply(lambda x: ','.join(map(str, x)))\n",
        "else:\n",
        "    Patents_citing_UK_pubs['publication_ids'] = \"\"\n",
        "\n",
        "# Count patents per grant and enrich the original dataset\n",
        "def patents_citing_pubsids(pubsids):\n",
        "  global Patents_citing_UK_pubs\n",
        "  return Patents_citing_UK_pubs[Patents_citing_UK_pubs['publication_ids'].str.contains(pubsids)]\n",
        "\n",
        "print(\"===\\nCounting patents citations per publication...\")\n",
        "\n",
        "l = []\n",
        "for x in progressbar(pubsids):\n",
        "  l.append(len(patents_citing_pubsids(x)))\n",
        "\n",
        "UK_dementia_publications['Citing patents'] = l\n",
        "\n",
        "print(\"===\\nDone\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzJLYBsIBe_1"
      },
      "outputs": [],
      "source": [
        "UK_dementia_publications.to_csv(\"/content/drive/MyDrive/Matilda thesis/UK dementia publications.csv\")\n",
        "UK_dementia_publications.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Jnsud4dzVX_"
      },
      "outputs": [],
      "source": [
        "UK_dementia_publications= pd.read_csv(\"/content/drive/MyDrive/Matilda thesis/UK dementia publications.csv\")\n",
        "UK_dementia_publications.drop('Unnamed: 0', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xXyg9fm9LkX"
      },
      "source": [
        "To check which publications are cited by patents and those not cited by patents use code below, this can also be checked in excel using the filter option"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Quna6IbLBcPF"
      },
      "outputs": [],
      "source": [
        "UK_publications_cited_by_patents = UK_dementia_publications[UK_dementia_publications['Citing patents'] > 0] # Dataframe with \"Citing Patents\" > 0\n",
        "UK_publications_NOT_cited_by_patents= UK_dementia_publications[UK_dementia_publications['Citing patents'] == 0] # Dataframe with \"Citing Patents\" = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPtgL-jpuK-F"
      },
      "outputs": [],
      "source": [
        "print(len(UK_publications_cited_by_patents))\n",
        "print(len(UK_publications_NOT_cited_by_patents))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prdQ4-0ySPbW"
      },
      "source": [
        "##PUBLICATIONS cited by clinical trials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYC9-uAZTdRz"
      },
      "source": [
        "###Add associated trials to each publication in the UK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idNc6rLlSbsK"
      },
      "outputs": [],
      "source": [
        "# pull out the grant IDs as a list\n",
        "pubsids = list(UK_dementia_publications[\"id\"])\n",
        "\n",
        "# Create a query and run through publications in chunks, there are too many results to process at once otherwise\n",
        "pubs_chunks_CT = dsl.query_iterative(f\"\"\"\n",
        "search publications\n",
        "in title_abstract_only for \"dementia OR alzheimer*\"\n",
        "where (research_org_countries = \"GB\"\n",
        "and year in [2000:2023])\n",
        "return publications[id]\"\"\").chunks(500)\n",
        "\n",
        "# Search for patents for the publications in the list created\n",
        "query_results_UK_with_CT_pubs = []\n",
        "\n",
        "for c in pubs_chunks_CT:\n",
        "\n",
        "      UK_pubsids_with_CT = json.dumps(list(pd.DataFrame(c).id))\n",
        "\n",
        "      query_results_UK_with_CT_pubs.append(\n",
        "\n",
        "                  dsl.query_iterative(f\"\"\"\n",
        "                        search clinical_trials\n",
        "                            where publication_ids in {UK_pubsids_with_CT}\n",
        "                            return clinical_trials[basics+publication_ids]\n",
        "                        \"\"\").as_dataframe()\n",
        "      )\n",
        "\n",
        "# Concatenate the patents to the publication list based on the id\n",
        "CT_citing_UK_pubs = pd.concat(query_results_UK_with_CT_pubs).\\\n",
        "   drop_duplicates(subset='id')\n",
        "\n",
        "if 'publication_ids' in CT_citing_UK_pubs:\n",
        "    # turning lists into strings to ensure compatibility with CSV loaded data\n",
        "    # see also: https://stackoverflow.com/questions/23111990/pandas-dataframe-stored-list-as-string-how-to-convert-back-to-list\n",
        "    CT_citing_UK_pubs['publication_ids'] = CT_citing_UK_pubs['publication_ids'].apply(lambda x: ','.join(map(str, x)))\n",
        "else:\n",
        "    CT_citing_UK_pubs['publication_ids'] = \"\"\n",
        "\n",
        "# count patents per grant and enrich the original dataset\n",
        "def CT_citing_pubsids(pubsids):\n",
        "  global CT_citing_UK_pubs\n",
        "  return CT_citing_UK_pubs[CT_citing_UK_pubs['publication_ids'].str.contains(pubsids)]\n",
        "\n",
        "print(\"===\\nCounting CT citations per publications...\")\n",
        "\n",
        "l = []\n",
        "for x in progressbar(pubsids):\n",
        "  l.append(len(CT_citing_pubsids(x)))\n",
        "\n",
        "UK_dementia_publications['Associated trials'] = l\n",
        "\n",
        "print(\"===\\nDone\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qplMr6FNTiAK"
      },
      "source": [
        "To check which publications are cited by clinical trials and those not cited by patents use code below, this can also be checked in excel using the filter option"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBlKp2O-SkMB"
      },
      "outputs": [],
      "source": [
        "UK_dementia_pubs_with_CT = UK_dementia_publications[UK_dementia_publications['Associated trials'] > 0] # Dataframe with \"Citing Patents\" > 0\n",
        "UK_dementia_pubs_NO_CT= UK_dementia_publications[UK_dementia_publications['Associated trials'] == 0] # Dataframe with \"Citing Patents\" = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKhbPBI_Stlm"
      },
      "outputs": [],
      "source": [
        "print(UK_dementia_pubs_with_CT.shape)\n",
        "print(UK_dementia_pubs_NO_CT.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## add labels"
      ],
      "metadata": {
        "id": "JppRPwanNbRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To add columns for your target label, df is your features dataframe WITH citing patents and Associated trials.\n",
        "# Assuming df is your DataFrame and 'Citing patents' and 'associated trials' are your columns\n",
        "#df['label_patents'] = df['Citing patents'].apply(lambda x: 1 if x > 0 else 0)\n",
        "#df['label_trials'] = df['Associated trials'].apply(lambda x: 1 if x > 0 else 0)"
      ],
      "metadata": {
        "id": "Ab-MKYkuNgZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Concepts"
      ],
      "metadata": {
        "id": "BMywRtEDgvjo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create concepts dataframe with concepts scores"
      ],
      "metadata": {
        "id": "TKaBAq7UCZDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Search for concepts and their scores\n",
        "Concepts_score = dsl.query_iterative(f\"\"\"\n",
        "search publications\n",
        "in title_abstract_only for \"dementia OR alzheimer*\"\n",
        "where (research_org_countries = \"GB\"\n",
        "and year in [2000:2023])\n",
        "return publications[id+concepts_scores]\"\"\").as_dataframe()\n",
        "Concepts_score = pd.DataFrame(Concepts_score)"
      ],
      "metadata": {
        "id": "aBV-4eoNvQUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# work with a copy of the results so you keep the original\n",
        "df1 = Concepts_score.copy()\n",
        "\n",
        "# this checks each row in df1, and drops any row that is not in a list format, and it resets the index if it drops a row\n",
        "i = 0\n",
        "while i < 38641:\n",
        "  if type(df1[\"concepts_scores\"].iloc[i]) is not list:\n",
        "    df1.drop([i], axis=0, inplace=True)\n",
        "  i+=1\n",
        "\n",
        "df1.reset_index(inplace=True)\n",
        "df1.drop(['index'], axis=1, inplace=True)\n",
        "df1\n"
      ],
      "metadata": {
        "id": "xhsNGJJu8X47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that generate a list of concepts where concept relevance is greater than 0.5\n",
        "# Param index - Index is the index in the dataframe\n",
        "def remove_below_50(index):\n",
        "  final = []\n",
        "  scores_lst = df1[\"concepts_scores\"].iloc[index]\n",
        "  if type(scores_lst) is not list:\n",
        "    df1.at[index,\"concepts_scores\"] = final\n",
        "    return final\n",
        "  for i in scores_lst:\n",
        "    if i['relevance'] >= 0.5:\n",
        "      final.append(i['concept'])\n",
        "\n",
        "  df1.at[index,\"concepts_scores\"] = final\n",
        "  return final\n",
        "\n",
        "for i in range(len(df1)):\n",
        "  remove_below_50(i)\n",
        "\n",
        "# finds lists that are length 0, removes them\n",
        "lst = []\n",
        "i = 0\n",
        "while i < len(df1):\n",
        "  if len(df1[\"concepts_scores\"].iloc[i])==0:\n",
        "    lst.append(i)\n",
        "  i+=1\n",
        "\n",
        "df1.drop(lst, axis=0, inplace=True)\n",
        "df1.reset_index(inplace=True)\n",
        "df1.drop(['index'], axis=1, inplace=True)\n",
        "df1\n",
        "\n",
        "#this rename the columns from concepts_scores to just concepts\n",
        "df1.rename(columns = {'concepts_scores':'concepts'}, inplace = True)"
      ],
      "metadata": {
        "id": "bA0ysDtM0uvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.to_csv(\"/content/drive/MyDrive/Matilda thesis/official/concepts list with relevance.csv\")"
      ],
      "metadata": {
        "id": "gzCxKIHbW7Oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv(\"/content/drive/MyDrive/Matilda thesis/official/concepts list with relevance.csv\")\n",
        "df1.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
        "\n",
        "#this removes all the unnecessary values in the dataframe\n",
        "for i in range(len(df1)):\n",
        "  lst = df1[\"concepts\"].iloc[i].strip('][').replace(\"\\'\",\"\").replace(\"\\\"\",\"\").split(', ')\n",
        "  df1.at[i,\"concepts\"] = lst\n",
        "\n",
        "df1"
      ],
      "metadata": {
        "id": "g-B5a9ZRXg8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "up to here we have a dataframe with concepts that have relevance above .5, no empty cells."
      ],
      "metadata": {
        "id": "8fPRxhmL39Vd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "finding all the unique concepts in df1 - dataframe with removed concepts scores below .5"
      ],
      "metadata": {
        "id": "zuoGkEYQWxj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = df1.copy()\n",
        "# search for all the unique concepts in the df1 dataframe\n",
        "unique_concepts = set()\n",
        "for concepts in data['concepts']:\n",
        "  for i in concepts:\n",
        "    unique_concepts.add(i)\n",
        "\n",
        "unique_concepts = list(unique_concepts)\n",
        "print(len(unique_concepts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ac8-opBvQJG",
        "outputId": "dd09ff75-3a88-4e00-e053-fa13e2aefc2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "go through unique concepts, check how often they appear"
      ],
      "metadata": {
        "id": "DaOryt2aJquC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_dict = {}\n",
        "\n",
        "for i in unique_concepts:\n",
        "  count_dict[i] = 0\n",
        "\n",
        "print(len(count_dict))\n",
        "\n",
        "for i in range(len(df1)):\n",
        "  for j in df1[\"concepts\"].iloc[i]:\n",
        "    count_dict[j] +=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6LemClMJcwF",
        "outputId": "31bc0405-859b-4629-94a6-67a43e838afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "concepts_count_prevalence = pd.DataFrame.from_dict(count_dict, orient='index')\n",
        "concepts_count_prevalence.to_csv(\"/content/drive/MyDrive/Matilda thesis/official/concepts count prevalence.csv\")"
      ],
      "metadata": {
        "id": "7hIGL6mMN3z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concepts_count_prevalence = pd.read_csv(\"/content/drive/MyDrive/Matilda thesis/official/concepts count prevalence.csv\")"
      ],
      "metadata": {
        "id": "z3kSq_vKUZ4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "remove all concepts that appear less than 20 times"
      ],
      "metadata": {
        "id": "HeAt37TuXnfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "higher_prevalence = concepts_count_prevalence.copy()\n",
        "higher_prevalence.rename(columns = {'Unnamed: 0':'Concept'}, inplace = True)\n",
        "higher_prevalence.rename(columns = {'0':'Count'}, inplace = True)\n",
        "\n",
        "higher_prevalence"
      ],
      "metadata": {
        "id": "3FT03UNlT2Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove all concepts that appear less than 20 times\n",
        "lst = []\n",
        "for i in range(len(higher_prevalence)):\n",
        "  if higher_prevalence[\"Count\"].iloc[i] < 20:\n",
        "    lst.append(i)\n",
        "\n",
        "higher_prevalence.drop(lst, axis=0, inplace=True)\n",
        "higher_prevalence.reset_index(inplace=True)\n",
        "higher_prevalence.drop(['index'], axis=1, inplace=True)\n",
        "\n",
        "print(len(higher_prevalence))\n",
        "higher_prevalence"
      ],
      "metadata": {
        "id": "3dkMQ--XVcm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst_concepts = higher_prevalence[\"Concept\"].values.tolist() #Turn Concept column in dataframe to a list\n",
        "\n",
        "for i in range(len(lst_concepts)):\n",
        "  better = lst_concepts[i].replace(\"\\'\",\"\")\n",
        "  lst_concepts[i] = better"
      ],
      "metadata": {
        "id": "_seVxWvxVccb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace the original dataframe with the new dataframe of only concepts that appear more than 20 (or 5) times and have relevance of more than 0.5\n",
        "for i in range(len(df1)):\n",
        "  lst = df1[\"concepts\"].iloc[i]\n",
        "  lst2 = []\n",
        "  for j in range(len(lst)):\n",
        "    if lst[j] in lst_concepts:\n",
        "      lst2.append(lst[j])\n",
        "  df1.at[i,\"concepts\"] = lst2"
      ],
      "metadata": {
        "id": "WDAsUGZoZBuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.to_csv(\"/content/drive/MyDrive/Matilda thesis/official/concepts appearance minimum 20.csv\")"
      ],
      "metadata": {
        "id": "3LCK2i5S8pPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv(\"/content/drive/MyDrive/Matilda thesis/official/concepts appearance minimum 20.csv\")\n",
        "df1.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
        "\n",
        "for i in range(len(df1)):\n",
        "  lst = df1[\"concepts\"].iloc[i].strip('][').replace(\"\\'\",\"\").replace(\"\\\"\",\"\").split(', ')\n",
        "  df1.at[i,\"concepts\"] = lst\n"
      ],
      "metadata": {
        "id": "ops74OI-_TaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "one hot encode df1 - for concepts prevalence 20 and relevance 0.5"
      ],
      "metadata": {
        "id": "EYyRms6ChhuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming df is your dataframe\n",
        "df = df1.copy()\n",
        "\n",
        "# Using the explode method, create a new dataframe where each concept is a separate row\n",
        "df_exploded = df.explode('concepts')\n",
        "\n",
        "# Strip any leading/trailing white space from the concepts\n",
        "df_exploded['concepts'] = df_exploded['concepts'].str.strip()\n",
        "\n",
        "# One-hot encode the exploded dataframe and group by id, using max as the aggregation function to avoid duplicate rows\n",
        "one_hot = pd.get_dummies(df_exploded, columns=['concepts']).groupby('id', as_index=False).max()\n",
        "\n",
        "# Display the resulting dataframe\n",
        "print(one_hot)\n"
      ],
      "metadata": {
        "id": "SFKC99eXhjT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot.to_csv(\"/content/drive/MyDrive/Matilda thesis/official/concepts one hot.csv\")"
      ],
      "metadata": {
        "id": "5XcHphdWivbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot = pd.read_csv(\"/content/drive/MyDrive/Matilda thesis/official/concepts one hot.csv\")"
      ],
      "metadata": {
        "id": "lo2whxcr2tkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot1 = one_hot.copy()\n",
        "one_hot1.rename(columns=lambda x: x[9:], inplace=True)"
      ],
      "metadata": {
        "id": "iGKkrVY5nnlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y6cagxQ7N4P"
      },
      "source": [
        "#ML data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## add the year to the dataframe"
      ],
      "metadata": {
        "id": "vZ6nZh4Mbtx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "years = dsl.query_iterative(f\"\"\"\n",
        "search publications\n",
        "in title_abstract_only for \"dementia OR alzheimer*\"\n",
        "where (research_org_countries = \"GB\"\n",
        "and year in [2000:2023])\n",
        "return publications[id+year]\n",
        "\"\"\").as_dataframe()"
      ],
      "metadata": {
        "id": "u0Ic0JCDbs9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "years = pd.DataFrame(years)"
      ],
      "metadata": {
        "id": "dGI4aryYckyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "years.to_csv(\"/content/drive/MyDrive/Matilda thesis/official/id + years.csv\")"
      ],
      "metadata": {
        "id": "QLQtn9yKdKYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "years = pd.read_csv(\"/content/drive/MyDrive/Matilda thesis/official/id + years.csv\")\n",
        "years['id'] = years['id'].apply(lambda x: x[4:])"
      ],
      "metadata": {
        "id": "OXlTc4qcelNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "merge years with entire feature table"
      ],
      "metadata": {
        "id": "xtD-lsQKdXrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Features_total = pd.read_csv(\"/content/drive/MyDrive/Matilda thesis/official/Features 2000-2023 clean for ML with labels.csv\")\n"
      ],
      "metadata": {
        "id": "R5jf2cTRdbRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Features_years_total = Features_total.merge(years, on='id')\n",
        "Features_years_total.drop(['Unnamed: 0_x', 'Unnamed: 0_y'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "xuICldjKduyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Features_years_total.to_csv(\"/content/drive/MyDrive/Matilda thesis/official/Features for ML with years.csv\")"
      ],
      "metadata": {
        "id": "0xFNG-Uces7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Category_hrcs_rac cleaning"
      ],
      "metadata": {
        "id": "PPn6pZHfTQD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Features_2000_2023 = pd.read_csv(\"/content/drive/MyDrive/Matilda thesis/official/UK dementia publications (5 - edited).csv\")"
      ],
      "metadata": {
        "id": "kl2EGvhjT1_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_hrcs_rac = Features_2000_2023[[\"id\", \"category_hrcs_rac\"]]\n",
        "category_hrcs_rac.columns"
      ],
      "metadata": {
        "id": "NcRRwg_aTURx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = category_hrcs_rac\n",
        "\n",
        "# Replace NaN values with '[]'\n",
        "df.loc[:, 'category_hrcs_rac'] = df['category_hrcs_rac'].fillna('[]')\n",
        "\n",
        "# Convert string representation of list of dicts to actual list of dicts\n",
        "df.loc[:, 'category_hrcs_rac'] = df['category_hrcs_rac'].apply(ast.literal_eval)\n",
        "\n",
        "# Extract the 'name' from each dictionary, remove the number prefix and join them with a comma\n",
        "df.loc[:, 'category_hrcs_rac'] = df['category_hrcs_rac'].apply(\n",
        "    lambda x: ', '.join([i['name'].split(' ', 1)[-1] for i in x])\n",
        ")\n",
        "\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "fg7EPM37WcNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = category_hrcs_rac"
      ],
      "metadata": {
        "id": "cZ4u0uC2WvoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_hrcs_rac.to_csv(\"/content/drive/MyDrive/Matilda thesis/category hrcs rac + ID.csv\")"
      ],
      "metadata": {
        "id": "trcMS-b-W252"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "merge with feature list"
      ],
      "metadata": {
        "id": "Ec1QpTQeXe35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Features_2000_2023_racclean = Features_2000_2023.merge(category_hrcs_rac, on=\"id\")"
      ],
      "metadata": {
        "id": "O3-0VE3YXejW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Features_2000_2023_racclean.to_csv(\"/content/drive/MyDrive/Matilda thesis/Features 2000-2023 with hrcs_rac cleaned.csv\")"
      ],
      "metadata": {
        "id": "QUPGK7y6X4YQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Features_2000_2023_racclean = pd.read_csv(\"/content/drive/MyDrive/Matilda thesis/Features 2000-2023 with hrcs_rac cleaned.csv\")"
      ],
      "metadata": {
        "id": "mE_Q0cMue3EW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### one hot encode rac"
      ],
      "metadata": {
        "id": "Lzy6w5qI2zXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id_rac = Features_total[['id', 'category_hrcs_rac_clean']]"
      ],
      "metadata": {
        "id": "jiE2UMj2243d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_rac.head()"
      ],
      "metadata": {
        "id": "okrTSezd3gOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_rac.to_csv(\"/content/drive/MyDrive/Matilda thesis/official/id and rac.csv\")"
      ],
      "metadata": {
        "id": "BlviwTVO3myq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_rac = pd.read_csv(\"/content/drive/MyDrive/Matilda thesis/official/id and rac.csv\")\n",
        "id_rac.drop(['Unnamed: 0.1', 'Unnamed: 0'], axis=1, inplace=True)\n",
        "id_rac"
      ],
      "metadata": {
        "id": "aujLYsBX4ZxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming df is your dataframe\n",
        "df = id_rac.copy()\n",
        "\n",
        "# Fill NaN values with an empty string\n",
        "df['category_hrcs_rac_clean'] = df['category_hrcs_rac_clean'].fillna('')\n",
        "\n",
        "# Split the concepts on commas and create a list of concepts\n",
        "df['category_hrcs_rac_clean'] = df['category_hrcs_rac_clean'].apply(lambda x: x.split(','))\n",
        "\n",
        "# Using the explode method, create a new dataframe where each concept is a separate row\n",
        "df_exploded = df.explode('category_hrcs_rac_clean')\n",
        "\n",
        "# Strip any leading/trailing white space from the concepts\n",
        "df_exploded['category_hrcs_rac_clean'] = df_exploded['category_hrcs_rac_clean'].str.strip()\n",
        "\n",
        "# One-hot encode the exploded dataframe and group by id, using max as the aggregation function to avoid duplicate rows\n",
        "one_hot_rac = pd.get_dummies(df_exploded, columns=['category_hrcs_rac_clean']).groupby('id', as_index=False).max()\n",
        "\n",
        "# Display the resulting dataframe\n",
        "print(one_hot_rac)"
      ],
      "metadata": {
        "id": "gvQmIyaN335u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_rac.to_csv(\"/content/drive/MyDrive/Matilda thesis/official/one hot encoding rac.csv\")"
      ],
      "metadata": {
        "id": "rW9Ze_ko57XR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_rac = pd.read_csv(\"/content/drive/MyDrive/Matilda thesis/official/one hot encoding rac.csv\")"
      ],
      "metadata": {
        "id": "eMW7_2WD8XT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Category_hra cleaning"
      ],
      "metadata": {
        "id": "IwIbyqm0a-Gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "category_hra= Features_2000_2023_racclean[[\"id\", \"category_hra\"]]\n",
        "category_hra.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PC2z9CT2bCUA",
        "outputId": "cde09dd5-46c9-4377-ce93-a84b9af751d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'category_hra'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "\n",
        "# First, we'll convert the string representations of lists/dicts into actual lists/dicts\n",
        "category_hra['category_hra'] = category_hra['category_hra'].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else np.nan)\n",
        "\n",
        "# Now, let's extract the 'name' key from each dictionary in the 'category_hra' column\n",
        "category_hra['category_hra'] = category_hra['category_hra'].apply(lambda x: x[0]['name'] if pd.notnull(x) else np.nan)\n",
        "\n",
        "# print the DataFrame\n",
        "print(category_hra)\n"
      ],
      "metadata": {
        "id": "nYptZLOIgVYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_hra.to_csv(\"/content/drive/MyDrive/Matilda thesis/category hra + ID.csv\")"
      ],
      "metadata": {
        "id": "eUHzuA1rbkIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "merge with feature list"
      ],
      "metadata": {
        "id": "PFuEijb3bsEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Features_2000_2023_rac_hra_clean = Features_2000_2023_racclean.merge(category_hra, on=\"id\")"
      ],
      "metadata": {
        "id": "N28KFAVcbpj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Features_2000_2023_rac_hra_clean.to_csv(\"/content/drive/MyDrive/Matilda thesis/Features 2000-2023 with hrcs_rac and hra cleaned.csv\")"
      ],
      "metadata": {
        "id": "poxU-ak0cByS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Category_rcdc cleaning"
      ],
      "metadata": {
        "id": "2btIp5xth51U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "category_rcdc= Features_2000_2023_rac_hra_clean[[\"id\", \"category_rcdc\"]]\n",
        "category_rcdc.columns\n",
        "len(category_rcdc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiGlLTwZhpbh",
        "outputId": "a771f578-3c29-43c9-f9d0-13a78ddfc506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'category_rcdc'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "import numpy as np\n",
        "\n",
        "# Fill NaN values with '[]'\n",
        "category_rcdc['category_rcdc'] = category_rcdc['category_rcdc'].fillna('[]')\n",
        "\n",
        "# Convert string representation of list of dicts to actual list of dicts\n",
        "category_rcdc['category_rcdc'] = category_rcdc['category_rcdc'].apply(ast.literal_eval)\n",
        "\n",
        "# Extract the 'name' value from each dict and join with comma\n",
        "category_rcdc['category_rcdc'] = category_rcdc['category_rcdc'].apply(lambda x: ', '.join([i['name'] for i in x]) if isinstance(x, list) else np.nan)\n",
        "\n",
        "print(category_rcdc)\n"
      ],
      "metadata": {
        "id": "IWSO43iMiLSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_rcdc.to_csv(\"/content/drive/MyDrive/Matilda thesis/category rcdc + ID.csv\")"
      ],
      "metadata": {
        "id": "97pusKVAkv40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "merge with features list"
      ],
      "metadata": {
        "id": "GIu9ozZek6oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Features_2000_2023_rac_hra_clean = pd.read_csv(\"/content/drive/MyDrive/Matilda thesis/Features 2000-2023 with hrcs_rac and hra cleaned.csv\")"
      ],
      "metadata": {
        "id": "tRCYvO8XlatH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Features_2000_2023_rac_hra_rcdc_clean = Features_2000_2023_rac_hra_clean.merge(category_rcdc, on=\"id\")"
      ],
      "metadata": {
        "id": "_AjpNHu6k_fJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Features_2000_2023_rac_hra_rcdc_clean.to_csv(\"/content/drive/MyDrive/Matilda thesis/Features 2000-2023 with hrcs_rac, hra and rcdc cleaned.csv\")"
      ],
      "metadata": {
        "id": "4QkthMaDlLrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## one hot encode rcdc"
      ],
      "metadata": {
        "id": "Sxff8Z_68d5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id_rcdc = Features_total[['id', 'category_rcdc_clean']]"
      ],
      "metadata": {
        "id": "os_N53qN8ox2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_rcdc.to_csv(\"/content/drive/MyDrive/Matilda thesis/official/id and rcdc.csv\")"
      ],
      "metadata": {
        "id": "CdUGNZwh8yI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_rcdc = pd.read_csv(\"/content/drive/MyDrive/Matilda thesis/official/id and rcdc.csv\")\n",
        "id_rcdc.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
        "id_rcdc"
      ],
      "metadata": {
        "id": "zu46uBuu85nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming df is your dataframe\n",
        "df = id_rcdc.copy()\n",
        "\n",
        "# Fill NaN values with an empty string\n",
        "df['category_rcdc_clean'] = df['category_rcdc_clean'].fillna('')\n",
        "\n",
        "# Split the concepts on commas and create a list of concepts\n",
        "df['category_rcdc_clean'] = df['category_rcdc_clean'].apply(lambda x: x.split(','))\n",
        "\n",
        "# Using the explode method, create a new dataframe where each concept is a separate row\n",
        "df_exploded = df.explode('category_rcdc_clean')\n",
        "\n",
        "# Strip any leading/trailing white space from the concepts\n",
        "df_exploded['category_rcdc_clean'] = df_exploded['category_rcdc_clean'].str.strip()\n",
        "\n",
        "# One-hot encode the exploded dataframe and group by id, using max as the aggregation function to avoid duplicate rows\n",
        "one_hot_rcdc = pd.get_dummies(df_exploded, columns=['category_rcdc_clean']).groupby('id', as_index=False).max()\n",
        "\n",
        "# Display the resulting dataframe\n",
        "print(one_hot_rcdc)"
      ],
      "metadata": {
        "id": "y9j7_ZRC9IyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_rcdc.to_csv(\"/content/drive/MyDrive/Matilda thesis/official/one hot encoding rcdc.csv\")"
      ],
      "metadata": {
        "id": "MYdu50kT9p8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## adding year published to dataframe"
      ],
      "metadata": {
        "id": "h-_BzcKASxFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pubs_cited = dsl.query_iterative(f\"\"\"\n",
        "search publications\n",
        "in title_abstract_only\n",
        "for \"dementia OR alzheimer*\"\n",
        "where (research_org_countries = \"GB\"\n",
        "and year in [2000:2023])\n",
        "return publications[id+times_cited+year]\"\"\").as_dataframe()\n",
        "pubs_cited = pd.DataFrame(pubs_cited)"
      ],
      "metadata": {
        "id": "eq-_4tZOK0iV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pubs_cited.to_csv(\"/content/drive/MyDrive/Matilda thesis/check pubs cited.csv\")"
      ],
      "metadata": {
        "id": "BM_s_svgOVSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Features = pd.read_csv(\"/content/drive/MyDrive/Matilda thesis/official/Features 2000-2023 clean for ML with labels.csv\")"
      ],
      "metadata": {
        "id": "2kaQFLkGOwWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pubs_cited"
      ],
      "metadata": {
        "id": "Dr50E48qQG93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pubs_cited = pd.read_csv(\"/content/drive/MyDrive/Matilda thesis/check pubs cited.csv\")\n",
        "pubs_cited.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "pubs_cited['id'] = pubs_cited['id'].apply(lambda x: x[4:])"
      ],
      "metadata": {
        "id": "OsG7mCHtRB1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Id_label = Features[['id', 'Citing patents']]\n",
        "Id_label.head()"
      ],
      "metadata": {
        "id": "BYxsFKyQPENl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pubs_cited['id'] = pubs_cited['id'].astype(str)\n",
        "pubs_cited['times_cited'] = pubs_cited['times_cited'].astype(str)\n",
        "pubs_cited['year'] = pubs_cited['year'].astype(str)\n",
        "Id_label['id'] = Id_label['id'].astype(str)\n",
        "Id_label['Citing patents'] = Id_label['Citing patents'].astype(str)"
      ],
      "metadata": {
        "id": "r73reyoIP0Sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_timescited = pubs_cited.merge(Id_label, on='id')\n",
        "label_timescited"
      ],
      "metadata": {
        "id": "BSBW4ozdOszL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_timescited.to_csv(\"/content/drive/MyDrive/Matilda thesis/official/check label and times cited.csv\")"
      ],
      "metadata": {
        "id": "mBxnOtOXQc7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TSVD concepts"
      ],
      "metadata": {
        "id": "TgbzrTzQ2goO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_matrix = csr_matrix(one_hot1)\n",
        "n_components = 20  # Choose thenumber of components based on your requirements\n",
        "svd = TruncatedSVD(n_components=n_components)\n",
        "embeddings = svd.fit_transform(sparse_matrix)\n",
        "embeddings.shape"
      ],
      "metadata": {
        "id": "SslYVfvW22dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = pd.DataFrame(embeddings)\n",
        "embeddings['id'] = df1['id']\n",
        "embeddings['id'] = embeddings['id'].apply(lambda x: x[4:])"
      ],
      "metadata": {
        "id": "TyCxlWhK28MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.to_csv(\"/content/drive/MyDrive/Matilda thesis/official/TSVD.csv\")"
      ],
      "metadata": {
        "id": "U_KvdnE33APV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## t-sne concepts"
      ],
      "metadata": {
        "id": "HzMQQ8ID3CtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply t-SNE to the dataset\n",
        "tsne = TSNE(n_components=3, init=\"random\")\n",
        "tsne_result = tsne.fit_transform(one_hot1)\n",
        "print(tsne_result.shape)\n",
        "print(tsne_result)\n",
        "print(type(tsne_result.shape))"
      ],
      "metadata": {
        "id": "eqwOz_7Z3Ev8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv(\"/content/drive/MyDrive/Matilda thesis/official/Features 2000-2023 clean for ML patents (3).csv\")"
      ],
      "metadata": {
        "id": "CJx0_-l_3LMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_id = df2[['id', 'Label']]\n",
        "label_id\n",
        "\n",
        "label_id['id'] = label_id['id'].apply(lambda x: str(x))"
      ],
      "metadata": {
        "id": "DdZOM7Y73NMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a,b,c = zip(*tsne_result)\n",
        "\n",
        "data = df1.copy()\n",
        "\n",
        "data.drop(['concepts'], axis=1,inplace=True)\n",
        "\n",
        "a = list(a)\n",
        "b = list(b)\n",
        "c = list(c)\n",
        "\n",
        "data['a'] =  a\n",
        "data['b'] =  b\n",
        "data['c'] =  c\n",
        "\n",
        "data['id'] = data['id'].apply(lambda x: x[4:])\n",
        "\n",
        "data = data.merge(label_id, on='id')\n",
        "data.to_csv(\"/content/drive/MyDrive/Matilda thesis/official/data concepts tsne ML.csv\")"
      ],
      "metadata": {
        "id": "WVy0bUBy3P8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = data.copy()\n",
        "data1.drop(['id'],axis=1,inplace=True)\n",
        "data1"
      ],
      "metadata": {
        "id": "Wzeab7jQ3Viq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## t-sne category rcdc"
      ],
      "metadata": {
        "id": "xSCrHTMB3anT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_rcdc = pd.read_csv(\"/content/drive/MyDrive/Matilda thesis/official/one hot encoding rcdc.csv\")\n",
        "one_hot_rcdc.rename(columns=lambda x: x[20:], inplace=True)\n",
        "one_hot_rcdc.drop(['','',''],axis=1,inplace=True)\n",
        "one_hot_rcdc.columns"
      ],
      "metadata": {
        "id": "LcTkdj-43d4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply t-SNE to the dataset\n",
        "tsne_rcdc = TSNE(n_components=3, init=\"random\")\n",
        "tsne_result_rcdc = tsne.fit_transform(one_hot_rcdc)\n",
        "tsne_result_rcdc.shape"
      ],
      "metadata": {
        "id": "uMPHyyzo3g70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv(\"/content/drive/MyDrive/Matilda thesis/official/Features 2000-2023 clean for ML patents (3).csv\")"
      ],
      "metadata": {
        "id": "WNe2kxpw3i93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_id = df2[['id', 'Label']]\n",
        "label_id\n",
        "\n",
        "label_id['id'] = label_id['id'].apply(lambda x: str(x))"
      ],
      "metadata": {
        "id": "llqse59l3kuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rcdc_nested = pd.read_csv(\"/content/drive/MyDrive/Matilda thesis/official/id and rcdc.csv\")"
      ],
      "metadata": {
        "id": "sCXVfWlS3net"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l,m,n = zip(*tsne_result_rcdc)\n",
        "\n",
        "data = rcdc_nested.copy()\n",
        "\n",
        "data.drop(['category_rcdc_clean'], axis=1,inplace=True)\n",
        "\n",
        "a = list(l)\n",
        "b = list(m)\n",
        "c = list(n)\n",
        "\n",
        "data['l'] =  l\n",
        "data['m'] =  m\n",
        "data['n'] =  n\n",
        "\n",
        "\n",
        "rcdc_nested['id'] = rcdc_nested['id'].astype(str)\n",
        "rcdc_nested['category_rcdc_clean'] = rcdc_nested['category_rcdc_clean'].astype(str)\n",
        "label_id['Label'] = label_id['Label'].astype(str)\n",
        "label_id['id'] = label_id['id'].astype(str)\n",
        "\n",
        "data = data.merge(label_id, on='id')\n",
        "data.to_csv(\"/content/drive/MyDrive/Matilda thesis/official/category rcdc tsne ML.csv\")"
      ],
      "metadata": {
        "id": "l9sRdzyT3pwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/Matilda thesis/official/category rcdc tsne ML.csv\")\n",
        "data.drop(['Unnamed: 0', 'Label', 'Unnamed: 0.1'],axis=1,inplace=True)\n",
        "data"
      ],
      "metadata": {
        "id": "J68T8mZG3sU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = data.copy()\n",
        "data1.drop(['id', 'Unnamed: 0'],axis=1,inplace=True)\n",
        "data1"
      ],
      "metadata": {
        "id": "XBtrX9gP3z7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check of data after cleaning"
      ],
      "metadata": {
        "id": "0RMPDTM15P2I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Features check"
      ],
      "metadata": {
        "id": "Wf9iuOuS8hIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PUB_ID= \"pub.1131066542\"\n",
        "\n",
        "q = dsl.query(f\"\"\"\n",
        "search publications\n",
        "where id = \"{PUB_ID}\"\n",
        "return publications[basics+id+category_hrcs_rac+category_hra+category_rcdc+mesh_terms+authors_count+open_access+recent_citations+times_cited+altmetric+supporting_grant_ids+relative_citation_ratio]\"\"\").as_dataframe()\n",
        "q"
      ],
      "metadata": {
        "id": "0rY8LjT76QpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## concepts check"
      ],
      "metadata": {
        "id": "L6os5OYegnQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PUB_ID= \"pub.1029063222\"\n",
        "\n",
        "q = dsl.query(f\"\"\"\n",
        "search publications\n",
        "where id = \"{PUB_ID}\"\n",
        "return publications[id+title+abstract+concepts_scores]\"\"\").as_dataframe()\n",
        "q"
      ],
      "metadata": {
        "id": "NJ6pj6gkgmic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hrcs_rac check"
      ],
      "metadata": {
        "id": "VoDEK0hUzMyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PUB_ID= \"pub.1090797659\"\n",
        "\n",
        "q = dsl.query(f\"\"\"\n",
        "search publications\n",
        "where id = \"{PUB_ID}\"\n",
        "return publications[id+category_hrcs_rac]\"\"\").as_dataframe()\n",
        "q"
      ],
      "metadata": {
        "id": "v6RGfiNrzO_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hra check"
      ],
      "metadata": {
        "id": "aq83mQPu0xwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PUB_ID= \"pub.1020401106\"\n",
        "\n",
        "q = dsl.query(f\"\"\"\n",
        "search publications\n",
        "where id = \"{PUB_ID}\"\n",
        "return publications[id+category_hra]\"\"\").as_dataframe()\n",
        "q"
      ],
      "metadata": {
        "id": "X-ebVgse0xJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## rcdc check"
      ],
      "metadata": {
        "id": "wmbPC0X8wz-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PUB_ID= \"pub.1020401106\"\n",
        "\n",
        "q = dsl.query(f\"\"\"\n",
        "search publications\n",
        "where id = \"{PUB_ID}\"\n",
        "return publications[id+category_rcdc]\"\"\").as_dataframe()\n",
        "q"
      ],
      "metadata": {
        "id": "ZPZijPEFw128"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## concepts NESTED with label"
      ],
      "metadata": {
        "id": "WzP2UXY1W-HK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the cleaned features file, create a label column based on citing patents and associated trials: if there are 0 patents, the label is 0, if there are more than 0 patents, the label is 1. The same goes for clinical trials"
      ],
      "metadata": {
        "id": "o9ocTDk6xAQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Features_label_patentsML = pd.read_csv(\"/content/drive/MyDrive/Matilda thesis/official/Features 2000-2023 clean for ML patents (3).csv\")"
      ],
      "metadata": {
        "id": "YK0cIb8YXBBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select only the id and the label from the features list\n",
        "ID_label = Features_label_patentsML[[\"id\", \"Label\"]]\n",
        "ID_label.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjOE4WZ9XRlT",
        "outputId": "a9c517a2-d2ed-4a3c-b099-7ba61b3d927a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'Label'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the ID_label into a string\n",
        "ID_label['id'] = ID_label['id'].astype(str)\n",
        "len(ID_label)"
      ],
      "metadata": {
        "id": "CXi1AJNkbtfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Concepts_nested = pd.read_csv(\"/content/drive/MyDrive/Matilda thesis/official/concepts nested 2000-2023 3.csv\")"
      ],
      "metadata": {
        "id": "0rd7a32iXxFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Concepts_nested.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "md9WryciYXPt",
        "outputId": "058cdfca-06dc-4536-d308-e00ad6211462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'concepts'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Concepts_nested['id'] = Concepts_nested['id'].astype(str)"
      ],
      "metadata": {
        "id": "tQ-FqNLLcIOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Concepts_with_label = Concepts_nested.merge(ID_label, on=\"id\")"
      ],
      "metadata": {
        "id": "erIkhn-ZX7cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Concepts_with_label.to_csv(\"/content/drive/MyDrive/Matilda thesis/official/Concepts with label 2000-2023.csv\")"
      ],
      "metadata": {
        "id": "ihoOjcaMcoNR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "collapsed_sections": [
        "VhOOop8KOtU2",
        "NvemdwG3KH68",
        "vZ6nZh4Mbtx1",
        "PPn6pZHfTQD_",
        "Lzy6w5qI2zXI",
        "IwIbyqm0a-Gh",
        "2btIp5xth51U",
        "Sxff8Z_68d5v",
        "h-_BzcKASxFB",
        "Wf9iuOuS8hIM",
        "L6os5OYegnQZ",
        "VoDEK0hUzMyx",
        "aq83mQPu0xwB",
        "wmbPC0X8wz-w",
        "BIqNM_f8UwmQ",
        "sn_Y0SOcU5qf",
        "AU7oR5ug8fu-",
        "x0fC5ryq8ijN",
        "FQ_VRDZm8ljZ",
        "WzP2UXY1W-HK"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}